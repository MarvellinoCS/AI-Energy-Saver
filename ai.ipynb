{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UT3tsyv6ART1","executionInfo":{"status":"ok","timestamp":1703718258261,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"932bd745-3c3a-4fef-8600-40dafe722ab6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Dec 27 23:04:19 2023       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["import os\n","HOME = os.getcwd()\n","print(HOME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btoxRB7nCKrK","executionInfo":{"status":"ok","timestamp":1703718262235,"user_tz":-480,"elapsed":2,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"fef6dfef-f6df-40d4-ab35-3d08b7a233e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!pip install ultralytics==8.0.20\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7x_wQTWzCT5m","executionInfo":{"status":"ok","timestamp":1703718285497,"user_tz":-480,"elapsed":19279,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"58ae26e5-242e-4c7a-e21b-371d7c69484f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","from IPython.display import display, Image"],"metadata":{"id":"UzV-7zkVCfwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'\n"],"metadata":{"id":"-Xn1_iM6DbYc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703718583320,"user_tz":-480,"elapsed":6840,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"97289d1d-9baa-478c-c065-968b203f215c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 212, in entrypoint\n","    raise argument_error(a)\n","SyntaxError: 'PKM/runs/detect/train/weights/best.pt' is not a valid YOLO argument.\n","\n","    YOLOv8 'yolo' CLI commands use the following syntax:\n","\n","        yolo TASK MODE ARGS\n","\n","        Where   TASK (optional) is one of [detect, segment, classify]\n","                MODE (required) is one of [train, val, predict, export]\n","                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n","                    See all ARGS at https://docs.ultralytics.com/cfg or with 'yolo cfg'\n","\n","    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n","        yolo detect train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n","\n","    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n","        yolo segment predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320\n","\n","    3. Val a pretrained detection model at batch-size 1 and image size 640:\n","        yolo detect val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n","\n","    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n","        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n","\n","    5. Run special commands:\n","        yolo help\n","        yolo checks\n","        yolo version\n","        yolo settings\n","        yolo copy-cfg\n","        yolo cfg\n","\n","    Docs: https://docs.ultralytics.com/cli\n","    Community: https://community.ultralytics.com\n","    GitHub: https://github.com/ultralytics/ultralytics\n","    \n"]}]},{"cell_type":"markdown","source":["Testing yolonya"],"metadata":{"id":"BmdxkeXrq_66"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"MKttvFG4riJ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703718394134,"user_tz":-480,"elapsed":2571,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"3171ec77-cc2b-482b-e88f-9a575b978753"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/AI PKM"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hrbO1v2ut22O","executionInfo":{"status":"ok","timestamp":1703718333548,"user_tz":-480,"elapsed":8,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"5e710cef-5a25-48ff-952b-d0353701fed9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AI PKM\n"]}]},{"cell_type":"code","source":["!ls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15pQ81kbuesT","executionInfo":{"status":"ok","timestamp":1703718336856,"user_tz":-480,"elapsed":308,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"61708726-f580-4f45-a3ac-5f5262a2ce51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" ai.ipynb   archive  'Copy of ai.ipynb'   data.yaml  'Dokumentasi '   runs\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/AI PKM\n","\n","!yolo task=detect mode=train model=yolov8s.pt data= data.yaml epochs=25 imgsz=900 plots=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T25ZEsxhuqIl","executionInfo":{"status":"ok","timestamp":1703589059636,"user_tz":-480,"elapsed":364189,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"2b7fc089-2ab5-49c0-dd3d-2978e37b3189"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AI PKM\n","Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.yaml, data=data.yaml, epochs=25, patience=50, batch=16, imgsz=900, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/train\n","2023-12-26 11:05:02.227941: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-26 11:05:02.227989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-26 11:05:02.229482: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.Detect                [1, [128, 256, 512]]          \n","Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","WARNING ‚ö†Ô∏è --img-size [900] must be multiple of max stride 32, updating to [928]\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/AI PKM/archive/train/labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100% 100/100 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/AI PKM/archive/val/labels.cache... 101 images, 0 backgrounds, 0 corrupt: 100% 101/101 [00:00<?, ?it/s]\n","Image sizes 928 train, 928 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/25      8.23G      1.261      7.066      1.521          5        928: 100% 7/7 [00:14<00:00,  2.05s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.34it/s]\n","                   all        101        153     0.0429      0.536      0.041     0.0163\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/25       9.9G      1.177       4.78      1.444          8        928: 100% 7/7 [00:11<00:00,  1.60s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.49it/s]\n","                   all        101        153      0.903      0.771      0.866      0.393\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/25      9.91G      1.142      1.353      1.394         13        928: 100% 7/7 [00:11<00:00,  1.63s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.53it/s]\n","                   all        101        153      0.865      0.876      0.929      0.423\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/25      9.91G      1.046      0.953      1.316         13        928: 100% 7/7 [00:11<00:00,  1.58s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.42it/s]\n","                   all        101        153      0.858      0.876      0.926      0.415\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/25      9.92G      1.031     0.8668      1.273          7        928: 100% 7/7 [00:10<00:00,  1.49s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.23it/s]\n","                   all        101        153      0.922      0.902       0.95      0.441\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/25      9.92G      1.047     0.7504      1.277         18        928: 100% 7/7 [00:10<00:00,  1.52s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.19it/s]\n","                   all        101        153      0.969      0.823      0.942      0.441\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/25      9.92G      1.066     0.7431       1.31         13        928: 100% 7/7 [00:09<00:00,  1.38s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.05it/s]\n","                   all        101        153      0.868      0.813      0.906      0.417\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/25      9.92G     0.9818     0.6732      1.235         10        928: 100% 7/7 [00:09<00:00,  1.38s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.12it/s]\n","                   all        101        153      0.858      0.827      0.909      0.361\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/25      9.92G     0.9357     0.6811      1.212         13        928: 100% 7/7 [00:09<00:00,  1.34s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.16it/s]\n","                   all        101        153      0.849      0.697      0.811      0.329\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/25      9.92G     0.8723     0.6694      1.179         12        928: 100% 7/7 [00:09<00:00,  1.39s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.31it/s]\n","                   all        101        153      0.821      0.706      0.802      0.315\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/25      9.92G     0.9512     0.6603      1.165         13        928: 100% 7/7 [00:10<00:00,  1.51s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.48it/s]\n","                   all        101        153      0.923      0.787      0.894       0.35\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/25      9.92G     0.9259     0.6743      1.187         10        928: 100% 7/7 [00:10<00:00,  1.51s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.49it/s]\n","                   all        101        153      0.877      0.647       0.77      0.323\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/25      9.92G     0.8904     0.7072      1.201         10        928: 100% 7/7 [00:11<00:00,  1.62s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.54it/s]\n","                   all        101        153      0.857      0.654      0.787       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/25      9.92G     0.9056     0.7005      1.139         10        928: 100% 7/7 [00:11<00:00,  1.58s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.51it/s]\n","                   all        101        153      0.862      0.784      0.861      0.358\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/25      9.92G     0.8939     0.6125      1.152         12        928: 100% 7/7 [00:11<00:00,  1.70s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.51it/s]\n","                   all        101        153      0.899      0.745      0.838      0.323\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/25      9.92G     0.8962     0.6594      1.277          4        928: 100% 7/7 [00:09<00:00,  1.42s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.56it/s]\n","                   all        101        153      0.837      0.824       0.87      0.367\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/25      9.92G     0.8012     0.5455      1.136          6        928: 100% 7/7 [00:06<00:00,  1.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.16it/s]\n","                   all        101        153      0.866      0.745      0.828      0.353\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/25      9.92G     0.8371     0.5733      1.133         10        928: 100% 7/7 [00:05<00:00,  1.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.33it/s]\n","                   all        101        153      0.838      0.677       0.79      0.321\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/25      9.92G     0.8018     0.5147      1.139          6        928: 100% 7/7 [00:07<00:00,  1.00s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.45it/s]\n","                   all        101        153      0.867      0.765      0.868      0.327\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/25      9.92G     0.7658     0.4848      1.122          5        928: 100% 7/7 [00:06<00:00,  1.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.31it/s]\n","                   all        101        153       0.96      0.752      0.891      0.381\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/25      9.92G     0.7356     0.4688      1.076          6        928: 100% 7/7 [00:06<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.32it/s]\n","                   all        101        153      0.932      0.797      0.909      0.387\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/25      9.92G     0.6932     0.4698      1.056          5        928: 100% 7/7 [00:06<00:00,  1.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.50it/s]\n","                   all        101        153      0.925       0.81        0.9       0.38\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/25      9.92G     0.7279     0.4795      1.062          7        928: 100% 7/7 [00:06<00:00,  1.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:03<00:00,  1.22it/s]\n","                   all        101        153      0.884      0.837      0.894       0.37\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/25      9.92G     0.6682     0.4389      1.062          4        928: 100% 7/7 [00:05<00:00,  1.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.37it/s]\n","                   all        101        153      0.906      0.837      0.903      0.398\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/25      9.92G     0.6512     0.4177      1.057          5        928: 100% 7/7 [00:07<00:00,  1.06s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:05<00:00,  1.30s/it]\n","                   all        101        153      0.893      0.843      0.905      0.398\n","\n","25 epochs completed in 0.094 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 22.6MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 22.6MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:04<00:00,  1.21s/it]\n","                   all        101        153      0.923      0.902       0.95      0.442\n","Speed: 0.5ms pre-process, 10.8ms inference, 0.0ms loss, 5.3ms post-process per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n"]}]},{"cell_type":"code","source":["!ls runs/detect/train/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1BCbBhtuqv0","executionInfo":{"status":"ok","timestamp":1703589231685,"user_tz":-480,"elapsed":506,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"a9f393fd-1977-4933-f40d-7fb4bc4dd328"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["args.yaml\t\t\t\t\t     results.png\t    val_batch0_pred.jpg\n","confusion_matrix.png\t\t\t\t     train_batch0.jpg\t    val_batch1_labels.jpg\n","events.out.tfevents.1703588704.69dba600c91b.11549.0  train_batch105.jpg     val_batch1_pred.jpg\n","F1_curve.png\t\t\t\t\t     train_batch106.jpg     val_batch2_labels.jpg\n","P_curve.png\t\t\t\t\t     train_batch107.jpg     val_batch2_pred.jpg\n","PR_curve.png\t\t\t\t\t     train_batch1.jpg\t    weights\n","R_curve.png\t\t\t\t\t     train_batch2.jpg\n","results.csv\t\t\t\t\t     val_batch0_labels.jpg\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=data.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmJEdAEm1NAr","executionInfo":{"status":"ok","timestamp":1703589332635,"user_tz":-480,"elapsed":20411,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"72bfa6e6-f9f1-4d3e-e0dc-a3ea96c7058d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-26 11:15:17.738578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-26 11:15:17.738628: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-26 11:15:17.739964: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/AI PKM/archive/val/labels.cache... 101 images, 0 backgrounds, 0 corrupt: 100% 101/101 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:07<00:00,  1.09s/it]\n","                   all        101        153      0.922      0.902       0.95      0.444\n","Speed: 7.8ms pre-process, 24.8ms inference, 0.0ms loss, 11.4ms post-process per image\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt conf=0.25 source=archive/test/images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DCwAaEeI2Cws","executionInfo":{"status":"ok","timestamp":1703589498460,"user_tz":-480,"elapsed":17999,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"66df39b0-7606-4b46-b6c6-d8085b5eafca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-26 11:18:05.876141: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-26 11:18:05.876203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-26 11:18:05.877737: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","image 1/101 /content/drive/MyDrive/AI PKM/archive/test/images/279.png: 928x928 5 Persons, 29.4ms\n","image 2/101 /content/drive/MyDrive/AI PKM/archive/test/images/280.png: 928x928 1 Person, 29.4ms\n","image 3/101 /content/drive/MyDrive/AI PKM/archive/test/images/281.png: 928x928 1 Person, 29.2ms\n","image 4/101 /content/drive/MyDrive/AI PKM/archive/test/images/283.png: 928x928 1 Person, 29.2ms\n","image 5/101 /content/drive/MyDrive/AI PKM/archive/test/images/284.png: 928x928 1 Person, 29.3ms\n","image 6/101 /content/drive/MyDrive/AI PKM/archive/test/images/285.png: 928x928 5 Persons, 29.2ms\n","image 7/101 /content/drive/MyDrive/AI PKM/archive/test/images/286.png: 832x928 1 Person, 92.9ms\n","image 8/101 /content/drive/MyDrive/AI PKM/archive/test/images/287.png: 928x928 1 Person, 21.0ms\n","image 9/101 /content/drive/MyDrive/AI PKM/archive/test/images/288.png: 928x928 3 Persons, 20.4ms\n","image 10/101 /content/drive/MyDrive/AI PKM/archive/test/images/289.png: 928x928 1 Person, 20.5ms\n","image 11/101 /content/drive/MyDrive/AI PKM/archive/test/images/290.png: 928x928 1 Person, 20.4ms\n","image 12/101 /content/drive/MyDrive/AI PKM/archive/test/images/291.png: 928x928 1 Person, 20.4ms\n","image 13/101 /content/drive/MyDrive/AI PKM/archive/test/images/292.png: 928x928 1 Person, 20.5ms\n","image 14/101 /content/drive/MyDrive/AI PKM/archive/test/images/293.png: 928x928 1 Person, 15.3ms\n","image 15/101 /content/drive/MyDrive/AI PKM/archive/test/images/294.png: 928x928 1 Person, 15.8ms\n","image 16/101 /content/drive/MyDrive/AI PKM/archive/test/images/295.png: 928x928 1 Person, 15.8ms\n","image 17/101 /content/drive/MyDrive/AI PKM/archive/test/images/296.png: 928x928 1 Person, 15.3ms\n","image 18/101 /content/drive/MyDrive/AI PKM/archive/test/images/297.png: 736x928 4 Persons, 67.4ms\n","image 19/101 /content/drive/MyDrive/AI PKM/archive/test/images/298.png: 928x928 1 Person, 15.8ms\n","image 20/101 /content/drive/MyDrive/AI PKM/archive/test/images/299.png: 928x928 2 Persons, 15.7ms\n","image 21/101 /content/drive/MyDrive/AI PKM/archive/test/images/300.png: 928x928 2 Persons, 15.4ms\n","image 22/101 /content/drive/MyDrive/AI PKM/archive/test/images/301.png: 928x928 1 Person, 15.2ms\n","image 23/101 /content/drive/MyDrive/AI PKM/archive/test/images/302.png: 928x928 1 Person, 15.6ms\n","image 24/101 /content/drive/MyDrive/AI PKM/archive/test/images/303.png: 928x928 1 Person, 15.7ms\n","image 25/101 /content/drive/MyDrive/AI PKM/archive/test/images/304.png: 928x928 1 Person, 15.2ms\n","image 26/101 /content/drive/MyDrive/AI PKM/archive/test/images/305.png: 928x928 15.6ms\n","image 27/101 /content/drive/MyDrive/AI PKM/archive/test/images/306.png: 928x928 1 Person, 15.5ms\n","image 28/101 /content/drive/MyDrive/AI PKM/archive/test/images/307.png: 928x928 1 Person, 15.3ms\n","image 29/101 /content/drive/MyDrive/AI PKM/archive/test/images/308.png: 800x928 1 Person, 68.4ms\n","image 30/101 /content/drive/MyDrive/AI PKM/archive/test/images/309.png: 928x928 3 Persons, 15.2ms\n","image 31/101 /content/drive/MyDrive/AI PKM/archive/test/images/310.png: 928x928 1 Person, 14.7ms\n","image 32/101 /content/drive/MyDrive/AI PKM/archive/test/images/311.png: 928x928 1 Person, 14.7ms\n","image 33/101 /content/drive/MyDrive/AI PKM/archive/test/images/312.png: 928x928 2 Persons, 14.8ms\n","image 34/101 /content/drive/MyDrive/AI PKM/archive/test/images/313.png: 928x928 2 Persons, 15.8ms\n","image 35/101 /content/drive/MyDrive/AI PKM/archive/test/images/314.png: 928x928 2 Persons, 15.9ms\n","image 36/101 /content/drive/MyDrive/AI PKM/archive/test/images/315.png: 928x928 1 Person, 15.3ms\n","image 37/101 /content/drive/MyDrive/AI PKM/archive/test/images/316.png: 928x928 2 Persons, 14.9ms\n","image 38/101 /content/drive/MyDrive/AI PKM/archive/test/images/317.png: 928x928 1 Person, 15.9ms\n","image 39/101 /content/drive/MyDrive/AI PKM/archive/test/images/318.png: 928x928 1 Person, 15.7ms\n","image 40/101 /content/drive/MyDrive/AI PKM/archive/test/images/319.png: 928x928 1 Person, 15.0ms\n","image 41/101 /content/drive/MyDrive/AI PKM/archive/test/images/320.png: 928x928 2 Persons, 15.9ms\n","image 42/101 /content/drive/MyDrive/AI PKM/archive/test/images/322.png: 928x928 1 Person, 15.6ms\n","image 43/101 /content/drive/MyDrive/AI PKM/archive/test/images/323.png: 928x928 2 Persons, 14.9ms\n","image 44/101 /content/drive/MyDrive/AI PKM/archive/test/images/324.png: 928x928 2 Persons, 15.1ms\n","image 45/101 /content/drive/MyDrive/AI PKM/archive/test/images/325.png: 928x928 2 Persons, 16.0ms\n","image 46/101 /content/drive/MyDrive/AI PKM/archive/test/images/326.png: 928x928 1 Person, 15.8ms\n","image 47/101 /content/drive/MyDrive/AI PKM/archive/test/images/327.png: 928x928 1 Person, 15.1ms\n","image 48/101 /content/drive/MyDrive/AI PKM/archive/test/images/328.png: 928x928 2 Persons, 15.0ms\n","image 49/101 /content/drive/MyDrive/AI PKM/archive/test/images/329.png: 928x928 2 Persons, 15.9ms\n","image 50/101 /content/drive/MyDrive/AI PKM/archive/test/images/330.png: 768x928 1 Person, 76.4ms\n","image 51/101 /content/drive/MyDrive/AI PKM/archive/test/images/331.png: 928x928 2 Persons, 15.3ms\n","image 52/101 /content/drive/MyDrive/AI PKM/archive/test/images/332.png: 928x928 6 Persons, 14.6ms\n","image 53/101 /content/drive/MyDrive/AI PKM/archive/test/images/333.png: 928x928 2 Persons, 15.8ms\n","image 54/101 /content/drive/MyDrive/AI PKM/archive/test/images/334.png: 928x928 2 Persons, 15.8ms\n","image 55/101 /content/drive/MyDrive/AI PKM/archive/test/images/335.png: 928x928 2 Persons, 15.1ms\n","image 56/101 /content/drive/MyDrive/AI PKM/archive/test/images/336.png: 928x928 1 Person, 15.1ms\n","image 57/101 /content/drive/MyDrive/AI PKM/archive/test/images/337.png: 928x928 1 Person, 16.1ms\n","image 58/101 /content/drive/MyDrive/AI PKM/archive/test/images/338.png: 928x928 4 Persons, 15.9ms\n","image 59/101 /content/drive/MyDrive/AI PKM/archive/test/images/339.png: 928x928 2 Persons, 15.2ms\n","image 60/101 /content/drive/MyDrive/AI PKM/archive/test/images/343.png: 928x928 1 Person, 15.0ms\n","image 61/101 /content/drive/MyDrive/AI PKM/archive/test/images/344.png: 928x928 2 Persons, 15.9ms\n","image 62/101 /content/drive/MyDrive/AI PKM/archive/test/images/345.png: 928x928 3 Persons, 15.3ms\n","image 63/101 /content/drive/MyDrive/AI PKM/archive/test/images/346.png: 928x928 1 Person, 15.4ms\n","image 64/101 /content/drive/MyDrive/AI PKM/archive/test/images/347.png: 928x928 1 Person, 15.5ms\n","image 65/101 /content/drive/MyDrive/AI PKM/archive/test/images/353.png: 800x928 2 Persons, 13.6ms\n","image 66/101 /content/drive/MyDrive/AI PKM/archive/test/images/354.png: 928x928 2 Persons, 15.6ms\n","image 67/101 /content/drive/MyDrive/AI PKM/archive/test/images/355.png: 928x928 1 Person, 14.8ms\n","image 68/101 /content/drive/MyDrive/AI PKM/archive/test/images/356.png: 928x928 2 Persons, 14.8ms\n","image 69/101 /content/drive/MyDrive/AI PKM/archive/test/images/357.png: 928x928 1 Person, 16.0ms\n","image 70/101 /content/drive/MyDrive/AI PKM/archive/test/images/358.png: 928x928 1 Person, 15.8ms\n","image 71/101 /content/drive/MyDrive/AI PKM/archive/test/images/359.png: 928x928 2 Persons, 15.0ms\n","image 72/101 /content/drive/MyDrive/AI PKM/archive/test/images/360.png: 928x928 1 Person, 15.2ms\n","image 73/101 /content/drive/MyDrive/AI PKM/archive/test/images/361.png: 928x928 1 Person, 16.0ms\n","image 74/101 /content/drive/MyDrive/AI PKM/archive/test/images/362.png: 928x928 2 Persons, 15.6ms\n","image 75/101 /content/drive/MyDrive/AI PKM/archive/test/images/363.png: 928x928 1 Person, 14.9ms\n","image 76/101 /content/drive/MyDrive/AI PKM/archive/test/images/364.png: 928x928 1 Person, 14.8ms\n","image 77/101 /content/drive/MyDrive/AI PKM/archive/test/images/365.png: 928x928 1 Person, 14.9ms\n","image 78/101 /content/drive/MyDrive/AI PKM/archive/test/images/366.png: 928x928 2 Persons, 15.5ms\n","image 79/101 /content/drive/MyDrive/AI PKM/archive/test/images/367.png: 928x928 1 Person, 15.1ms\n","image 80/101 /content/drive/MyDrive/AI PKM/archive/test/images/368.png: 928x928 1 Person, 14.9ms\n","image 81/101 /content/drive/MyDrive/AI PKM/archive/test/images/369.png: 928x928 1 Person, 15.8ms\n","image 82/101 /content/drive/MyDrive/AI PKM/archive/test/images/370.png: 928x928 1 Person, 15.1ms\n","image 83/101 /content/drive/MyDrive/AI PKM/archive/test/images/371.png: 928x928 1 Person, 15.7ms\n","image 84/101 /content/drive/MyDrive/AI PKM/archive/test/images/372.png: 928x928 4 Persons, 15.1ms\n","image 85/101 /content/drive/MyDrive/AI PKM/archive/test/images/373.png: 928x928 6 Persons, 15.3ms\n","image 86/101 /content/drive/MyDrive/AI PKM/archive/test/images/374.png: 928x928 15.5ms\n","image 87/101 /content/drive/MyDrive/AI PKM/archive/test/images/375.png: 736x928 3 Persons, 13.2ms\n","image 88/101 /content/drive/MyDrive/AI PKM/archive/test/images/376.png: 928x928 3 Persons, 15.7ms\n","image 89/101 /content/drive/MyDrive/AI PKM/archive/test/images/377.png: 928x928 2 Persons, 15.3ms\n","image 90/101 /content/drive/MyDrive/AI PKM/archive/test/images/378.png: 928x928 2 Persons, 14.9ms\n","image 91/101 /content/drive/MyDrive/AI PKM/archive/test/images/379.png: 928x928 1 Person, 15.7ms\n","image 92/101 /content/drive/MyDrive/AI PKM/archive/test/images/380.png: 928x928 1 Person, 15.4ms\n","image 93/101 /content/drive/MyDrive/AI PKM/archive/test/images/382.png: 928x928 1 Person, 15.0ms\n","image 94/101 /content/drive/MyDrive/AI PKM/archive/test/images/383.png: 928x928 1 Person, 15.4ms\n","image 95/101 /content/drive/MyDrive/AI PKM/archive/test/images/384.png: 928x928 1 Person, 15.5ms\n","image 96/101 /content/drive/MyDrive/AI PKM/archive/test/images/385.png: 928x928 1 Person, 15.0ms\n","image 97/101 /content/drive/MyDrive/AI PKM/archive/test/images/386.png: 800x928 1 Person, 13.6ms\n","image 98/101 /content/drive/MyDrive/AI PKM/archive/test/images/387.png: 928x928 2 Persons, 15.2ms\n","image 99/101 /content/drive/MyDrive/AI PKM/archive/test/images/388.png: 928x928 1 Person, 14.6ms\n","image 100/101 /content/drive/MyDrive/AI PKM/archive/test/images/389.png: 928x928 1 Person, 15.7ms\n","image 101/101 /content/drive/MyDrive/AI PKM/archive/test/images/390.png: 928x928 2 Persons, 15.6ms\n","Speed: 0.8ms pre-process, 18.9ms inference, 6.3ms postprocess per image at shape (1, 3, 928, 928)\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","import cv2\n","import math"],"metadata":{"id":"FqMrBxBiXcA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO\n","import cv2\n","import math\n","cap=cv2.VideoCapture(0)\n","\n","frame_width=int(cap.get(3))\n","frame_height = int(cap.get(4))\n","\n","model=YOLO(\"/content/drive/MyDrive/AI PKM/runs/detect/train/weights/best.pt\")\n","classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n","              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n","              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n","              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n","              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n","              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n","              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n","              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n","              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n","              \"teddy bear\", \"hair drier\", \"toothbrush\"\n","              ]\n","while True:\n","    success, img = cap.read()\n","    # Doing detections using YOLOv8 frame by frame\n","    #stream = True will use the generator and it is more efficient than normal\n","    results=model(img,stream=True)\n","    #Once we have the results we can check for individual bounding boxes and see how well it performs\n","    # Once we have have the results we will loop through them and we will have the bouning boxes for each of the result\n","    # we will loop through each of the bouning box\n","    for r in results:\n","        boxes=r.boxes\n","        for box in boxes:\n","            x1,y1,x2,y2=box.xyxy[0]\n","            #print(x1, y1, x2, y2)\n","            x1,y1,x2,y2=int(x1), int(y1), int(x2), int(y2)\n","            print(x1,y1,x2,y2)\n","            cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,255),3)\n","            #print(box.conf[0])\n","            conf=math.ceil((box.conf[0]*100))/100\n","            cls=int(box.cls[0])\n","            class_name=classNames[cls]\n","            label=f'{class_name}{conf}'\n","            t_size = cv2.getTextSize(label, 0, fontScale=1, thickness=2)[0]\n","            #print(t_size)\n","            c2 = x1 + t_size[0], y1 - t_size[1] - 3\n","            cv2.rectangle(img, (x1,y1), c2, [255,0,255], -1, cv2.LINE_AA)  # filled\n","            cv2.putText(img, label, (x1,y1-2),0, 1,[255,255,255], thickness=1,lineType=cv2.LINE_AA)\n","\n","    cv2.imshow(\"Image\", img)\n","    if cv2.waitKey(1) & 0xFF==ord('1'):\n","        break"],"metadata":{"id":"LK6tQQlwXhwv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!yolo predict model=/content/drive/MyDrive/AI PKM/runs/detect/train/weights/best.pt source='https://ultralytics.com/images/bus.jpg'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HuSQZ1Mziqzd","executionInfo":{"status":"ok","timestamp":1703718611676,"user_tz":-480,"elapsed":5796,"user":{"displayName":"Ferdhiandika","userId":"07280636163853767124"}},"outputId":"666a3dfe-2b86-459b-d506-8e2e0ab1a5b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 212, in entrypoint\n","    raise argument_error(a)\n","SyntaxError: 'PKM/runs/detect/train/weights/best.pt' is not a valid YOLO argument.\n","\n","    YOLOv8 'yolo' CLI commands use the following syntax:\n","\n","        yolo TASK MODE ARGS\n","\n","        Where   TASK (optional) is one of [detect, segment, classify]\n","                MODE (required) is one of [train, val, predict, export]\n","                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n","                    See all ARGS at https://docs.ultralytics.com/cfg or with 'yolo cfg'\n","\n","    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n","        yolo detect train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n","\n","    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n","        yolo segment predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320\n","\n","    3. Val a pretrained detection model at batch-size 1 and image size 640:\n","        yolo detect val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n","\n","    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n","        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n","\n","    5. Run special commands:\n","        yolo help\n","        yolo checks\n","        yolo version\n","        yolo settings\n","        yolo copy-cfg\n","        yolo cfg\n","\n","    Docs: https://docs.ultralytics.com/cli\n","    Community: https://community.ultralytics.com\n","    GitHub: https://github.com/ultralytics/ultralytics\n","    \n"]}]}]}